{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ordered-stamp",
   "metadata": {},
   "source": [
    "# OpenCV 주요클래스 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-turning",
   "metadata": {},
   "source": [
    "## 1. 이미지 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-objective",
   "metadata": {},
   "source": [
    "-이미지 파일의 형식은 수백 가지다.   \n",
    "-OpenCV에서 이미지를 다룰 경우 가장 많이 사용되는 이미지 형식은 JPG나 PNG 등의 래스터 그래픽스 이미지 파일 포맷이다.   \n",
    "-래스터 그래픽스: 비트맵 이미지를 뜻하며, 격자판의 형태로 각 격자마다 화소의 데이터가 담겨 있는 이미지 파일 포맷이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread(\n",
    "    fileName,\n",
    "    flags = cv2.IMREAD_COLOR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-place",
   "metadata": {},
   "source": [
    "### Q1. Python OpenCV에서는 이미지 입력을 어떤 함수로 나타내나요? 이 함수의 요소에는 무엇이 있나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-brake",
   "metadata": {},
   "source": [
    "-fileName(파일명): 경로를 포함한 입력 파일의 이름.   \n",
    "-flags(플래그): 입력된 파일을 어떻게 해석할지 결정한다.   \n",
    "\n",
    "-파일명에는 절대경로나 상대경로로 이미지 경로를 입력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-advantage",
   "metadata": {},
   "source": [
    "### Q2.절대 경로와 상대경로의 차이는 무엇인가요? 표현 방식은 어떻게 다른가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-creation",
   "metadata": {},
   "source": [
    "-절대경로: 절대경로란 어떤 파일이 가지고 있는 고유한 경로다.   \n",
    "-상대경로: 상대경로란 현재 프로그램의 위치를 기점으로 파악하는 경로다.   \n",
    "\n",
    "-표현방식   \n",
    "../ : 상위 경로   \n",
    "./ : 현재 경로   \n",
    "/ : 하위 경로\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-grace",
   "metadata": {},
   "source": [
    "### Q3. 플래그의 기본값과 옵션에는 어떤 것들이 있나요? 몇 가지를 정리해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-gathering",
   "metadata": {},
   "source": [
    "-플래그는 기본값을 색상값으로 가진다.   \n",
    "-기본 플래그는 8비트, 3채널, BGR 이미지로 불러오도록 돼 있다.   \n",
    "- (height, width, 3), np.uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-tackle",
   "metadata": {},
   "source": [
    "### Q4. 예제 4.2를 수행하고 결과를 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"OpenCV_Logo.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "print(src.ndim, src.shape, src.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-compiler",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-underground",
   "metadata": {},
   "source": [
    "## 2. 이미지 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-storage",
   "metadata": {},
   "source": [
    "-OpenCV의 HighGUI를 이용하면 윈도우를 생성해서 화면에 이미지를 출력하는 프로그램을 작성할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-facility",
   "metadata": {},
   "source": [
    "### Q5. python의 이미지 출력 함수는 어떤 모습인가요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\n",
    "    winname,\n",
    "    ndarray\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-assessment",
   "metadata": {},
   "source": [
    "### Q6. 하나의 이미지를 예제 4.4로 출력해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"OpenCV_Logo.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "cv2.namedWindow(\"src\", flags = cv2.WINDOW_FREERATIO)\n",
    "cv2.resizeWindow(\"src\", 400, 200)\n",
    "cv2.imshow(\"src\", src)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyWindow(\"src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-undergraduate",
   "metadata": {},
   "source": [
    "### Q7. 표 4.2를 참고하여, 윈도우의 사이즈를 조정해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"OpenCV_Logo.png\", cv2.IMREAD_GRAYSCALE)\n",
    "cv2.WINDOW_AUTOSIZE(\"src\", 600, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-phenomenon",
   "metadata": {},
   "source": [
    "### Q8. 표 4.3, 표 4.4를 읽어보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-jaguar",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-sampling",
   "metadata": {},
   "source": [
    "### 마우스 콜백"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-clinton",
   "metadata": {},
   "source": [
    "-콜백(Callback) 함수는 매개 변수를 통해 다른 함수를 전달받고, 이벤트가 발생할 때 매개 변수에 전달된 함수를 호출하는 역할을 한다.   \n",
    "-즉, 이벤트가 발생하면 다른 함수를 실행하는 함수를 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-currency",
   "metadata": {},
   "source": [
    "#### Python OpenCV의 마우스 콜백 설정 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.setMouseCallback(\n",
    "    windowName,\n",
    "    onMouse,\n",
    "    param = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-boring",
   "metadata": {},
   "source": [
    "#### Python OpenCV의 마우스 콜백 설정 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_name(\n",
    "    event,\n",
    "    x,\n",
    "    y,\n",
    "    flags,\n",
    "    param\n",
    "):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-dependence",
   "metadata": {},
   "source": [
    "### 예제 4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def mouse_event(event, x, y, flags, param):\n",
    "    global radius\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(param, (x,y), radius, (255,0,0), 2)\n",
    "        cv2.imshow(\"draw\", src)\n",
    "        \n",
    "    elif event == cv2.EVENT_MOUSEHWHEEL:\n",
    "        if flags > 0:\n",
    "            radius += 1\n",
    "        elif radius > 1:\n",
    "            radius -= 1\n",
    "            \n",
    "radius = 30\n",
    "src = np.full((500,500,3), 255, dtype=np.uint8)\n",
    "\n",
    "cv2.imshow(\"draw\", src)\n",
    "cv2.setMouseCallback(\"draw\", mouse_event, src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-determination",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-projector",
   "metadata": {},
   "source": [
    "## 3. 동영상 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-archives",
   "metadata": {},
   "source": [
    "### Q9. python OpenCV의 동영상 입력 클래스는 어떻게 표현되나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-party",
   "metadata": {},
   "source": [
    "-동영상 입력 클래스는 이미지 입력 함수와 동일한 기능을 한다.   \n",
    "-단, 동영상 입력은 클래스를 사용한다.   \n",
    "-생성자의 매개 변수인 파일명(filename)은 경로를 포함한 입력 파일의 이름이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-heath",
   "metadata": {},
   "source": [
    "### Q10. 예제 4.8을 활용하여 짧은 동영상을 출력해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modern-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(\"Star.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    \n",
    "    if(capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT)):\n",
    "        capture.open(\"Star.mp4\")\n",
    "        \n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "    if cv2.waitKey(33) == ord('q'): break\n",
    "        \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-allen",
   "metadata": {},
   "source": [
    "### FPS(Frame Per Second)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-reason",
   "metadata": {},
   "source": [
    "-동영상의 부드러움은 프레임이 초당 몇 장의 화면을 보여주느냐에 따라 결정되며, 이를 초당 프레임(FPS)이라 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-teddy",
   "metadata": {},
   "source": [
    "### Q11. 표 4.7,8을 확인하여 어떤 함수가 있는지 확인해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-kennedy",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-milwaukee",
   "metadata": {},
   "source": [
    "## 4. 카메라 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-surfing",
   "metadata": {},
   "source": [
    "-카메라 출력은 카메라가 스트리밍 형태로 동작할 때 사용한다.   \n",
    "-즉, 저장된 이미지나 동영상 파일이 아니라 데이터를 실시간으로 받아오고 분석해야 하는 경우 카메라를 이용해 데이터를 처리한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-olympus",
   "metadata": {},
   "source": [
    "### Q12. python opencv의 카메라 출력 클래스는 어떻게 표현되나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-banks",
   "metadata": {},
   "source": [
    "### Q13. 예제 4.10을 타이핑해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deluxe-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    if ret == True:\n",
    "        cv2.imshow(\"VideoFrame\", frame)\n",
    "        if cv2.waitKey(33) == ord(\"q\"): break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-acrylic",
   "metadata": {},
   "source": [
    "### Q14. Grab() 메서드와 Retrieve() 메서드에 대해 설명해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-discovery",
   "metadata": {},
   "source": [
    "-Grab() 메서드는 Read() 메서드와 비슷하지만 메모리 복사 작업을 수행사는 그랩(grab) 단계와 그랩 데이터를 디코딩하는 리트리브(retrieve) 단계로 나눠 처리한다.   \n",
    "-Retrieve() 메서드는 읽은 프레임을 디코딩해서 반환한다. 기존의 동영상을 읽는 방법과의 차이점은 플래그의 차이다. 플래그는 멀티 헤드 카메라가 라이브 스트림일 때 어떤 프레임을 가져올지 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-welding",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-basement",
   "metadata": {},
   "source": [
    "## 5. 이미지 연결"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-single",
   "metadata": {},
   "source": [
    "-이미지 연결은 서로 다른 이미지를 이어 붙여 하나의 이미지로 만드는 기능을 한다.   \n",
    "-주로, 서로 다른 이미지를 병합해 하나의 이미지로 만들거나, 알고리즘 적용 전 이미지와 알고리즘이 적용된 이미지를 상호 비교하기 위해 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-revelation",
   "metadata": {},
   "source": [
    "### 예제 4.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "burning-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "one = cv2.imread(\"one.jpg\")\n",
    "two = cv2.imread(\"two.jpg\")\n",
    "three = cv2.imread(\"three.jpg\")\n",
    "four = cv2.imread(\"four.jpg\")\n",
    "\n",
    "horizontal1 = np.full((50, one.shape[1],3), [0,0,0], dtype=np.uint8)\n",
    "horizontal2 = np.full((50, two.shape[1],3), [0,0,0], dtype=np.uint8)\n",
    "\n",
    "left = cv2.vconcat((one, horizontal1, three))\n",
    "# left = np.vstack((one, horizontal1, three))\n",
    "# right = cv2.vconcat((two, horizontal2, four))\n",
    "right = np.vstack((two, horizontal2, four))\n",
    "\n",
    "vertical = np.full((left.shape[0], 50, 3), 0, dtype=np.uint8)\n",
    "\n",
    "dst = cv2.hconcat((left, vertical, right))\n",
    "# dst = np.hstack((left, vertical, right))\n",
    "# dst = np.concatenate((left, line, right), axis=1)\n",
    "\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-wonder",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-adapter",
   "metadata": {},
   "source": [
    "## 6. 도형 그리기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-familiar",
   "metadata": {},
   "source": [
    "### 선형 타입"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-assignment",
   "metadata": {},
   "source": [
    "### Q15. 선형 타입 방식은 각각 어떤 방식인가요? 각각 어떻게 다른가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-meter",
   "metadata": {},
   "source": [
    "-4연결 방식: 선분에 픽셀을 할당할 때 다음에 할당될 위치로 오른쪽, 왼쪽, 위쪽, 아래쪽 영역만 고려한다.   \n",
    "-8연결 방식: 대각선 방향까지 추가돼 총 여덟개의 위치를 고려한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-smile",
   "metadata": {},
   "source": [
    "### 비트 시프트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-sierra",
   "metadata": {},
   "source": [
    "### Q16. 하나의 이미지를 불러오고, 이 이미지의 크기를 확인하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-nickel",
   "metadata": {},
   "source": [
    "### Q17. 직선, 사각형, 원, 호, 내부가 채워지지 않은 다각형, 내부가 채워진 다각형, 문자 클래스를 확인하고 어떻게 표현되는 지 적어보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-palmer",
   "metadata": {},
   "source": [
    "### Q18. 예제 4.10을 수행하고 결과를 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daily-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = np.zeros((768, 1366, 3), dtype=np.uint8)\n",
    "\n",
    "cv2.line(img, (100,100), (1200,100), (0,0,255), 3, cv2.LINE_AA)\n",
    "cv2.circle(img, (300,300), 50, (0,255,0), cv2.FILLED, cv2.LINE_4)\n",
    "cv2.rectangle(img, (500,200), (1000,400), (255,0,0), 5, cv2.LINE_8)\n",
    "cv2.ellipse(img, (1200,300), (100,50), 0, 90, 180, (255,255,0), 2)\n",
    "\n",
    "pts1 = np.array([[[100,500], [300,500], [200,600]], [[400,500], [500,500], [600,700]]])\n",
    "pts2 = np.array([[700,500], [800,500], [700,600]])\n",
    "cv2.polylines(img, pts1, True, (0,255,255), 2)\n",
    "cv2.fillPoly(img, [pts2], (255, 0, 255), cv2.LINE_AA)\n",
    "\n",
    "cv2.putText(img, \"OpenCV\", (900,600), cv2.FONT_HERSHEY_COMPLEX | cv2.FONT_ITALIC, 2, (255,255,255), 3)\n",
    "\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-syndrome",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
